Candidate Compressions A
    10,000 Candidates -> 2138s

Candidate Compressions B
    10,000 Candidates -> 320s

    Regenerate Classes of 2112 candidates (a)
    --> 23.14s

    Generate the first time (a)
    --> 125s

https://link.springer.com/article/10.1007/s10801-021-01084-0
^^ 
great resource, contains table of pgp up to length 40 up to equivalence

//11553

- https://archive.org/details/introductiontoko00limi_695
explains why probability is not the right concept to characterize the randomness of a sequence
first chapter


- changed the way the equivalence classes are checked for a sequence already found
- touch on previous slowdown during runtime, whereas now there is a speedup
- order 32 now takes the same time as order 26
- order 34 will probably take the time estimated previously for order 32
- found neat resource with a table of pbp up to length 40 
https://link.springer.com/article/10.1007/s10801-021-01084-0
- touch on compression generation results
- touch on how using equivalences on pairs will now probably result in speedup due to the significant matching time
- ask about the procedure for decompressing sequences ?? if we use one ??
- ask for title of project